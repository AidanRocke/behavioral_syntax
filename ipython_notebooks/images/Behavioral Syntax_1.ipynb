{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##This is a python exploration of the paper 'Changes in postural syntax characterize sensory modulation and natural variation of C. Elegans locomotion' co-authored by RF Shwarz, Andre Brown, William Schafer and many others. Below are the main ideas:\n",
    "1. animal tracking can increasingly be performed automatically but an outstanding challenge is finding ways to represent these behavioral data\n",
    "2. the following paper considers the idea that locomotion is driven by shape changes coordinated by the nervous system through time\n",
    "3. At any given moment the current worm posture can be approximated by the closest matching template from a pre-defined set of postures(i.e. kNN was used) obtained using K-means++ clustering. This is analogous to constructing a histogram where discrete bins are used to represent data drawn from a continuous distribution.\n",
    "4. With 90 template postures it's possible to capture around 83% of the postural variance and this opens up the possibility that NLP and bioinformatic methods can then be used to analyze worm locomotion. \n",
    "\n",
    "-some of the above points are taken directly from the above paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Kmeans++ clustering\n",
    "1. The similarity measure between postures and skeletons that was used was the tangent angle distance measure. \n",
    "2. Non-trivial(and positive) gain in R2(variance explained) between number of templates was used to determine when to stop increasing the number of templates. i.e. the elbow method was used. \n",
    "3. sklearn was used for Kmeans++ clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#below is the transformation used to get tangent angles from worm skeletons:\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "dX = np.diff(x, n=1, axis=0)\n",
    "dY = np.diff(y, n=1, axis=0)\n",
    "\n",
    "# calculate tangent angles.  atan2 uses angles from -pi to pi instead...\n",
    "# of atan which uses the range -pi/2 to pi/2.\n",
    "angles = np.arctan2(dY, dX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#once we've got all the angle arrays together, we can apply the positive R2 gain decision rule.\n",
    "#mean_r_sq() is a function called by decision_rule() as many times as the R2 gain is greater \n",
    "#than a pre-defined delta(greater than zero). \n",
    "\n",
    "import numpy as np\n",
    "from sklearn import manifold, cluster\n",
    "\n",
    "def mean_r_sq(k):\n",
    "    kmeans = cluster.KMeans(init='k-means++',n_clusters=k,max_iter=1000)\n",
    "    kmeans.fit(angles)\n",
    "    \n",
    "    labels = kmeans.labels_\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    \n",
    "    #compute average variance explained:\n",
    "    total_var = []\n",
    "    for i in range(len(centroids)):\n",
    "        total_var+= [np.corrcoef(centroids[i],j)[0][1]**2 for j in angle_0[np.where(labels == i)]]\n",
    "    \n",
    "    return [np.mean(total_var), centroids, labels]\n",
    "\n",
    "\n",
    "# prev = minimum cluster size\n",
    "# inc = incremental increase in cluster size k\n",
    "# delta = R_squared gain that is considered negligible\n",
    "def decision_rule(prev,inc,delta):\n",
    "    \n",
    "    while mean_r_sq(prev+inc)[0]-mean_r_sq(prev)[0] > delta:\n",
    "        prev = prev+inc\n",
    "        output = mean_r_sq(prev)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###In the paper, this resulted in the following template postures:\n",
    "<img src=\"http://localhost:8888/files/Untitled%20Folder%201/90_postures.png\">\n",
    "\n",
    "And we might be interested in looking at the tangent angle distance between these postures. Ideally\n",
    "they wouldn't be too close together. This is something we can approximately do with multidimensional \n",
    "scaling with the code below. It must be noted that in general for more than 4 points having more than\n",
    "two dimensions you need at least three dimensions for the distances to be preserved. Hence, for a large\n",
    "number of points MDS doesn't work very well. But, for the above postures the distances between the postures\n",
    "was actually preserved quite well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Below is the code used for MDS. The Bokeh plotting library is still growing\n",
    "#fast and interactivity is probably its greatest feature. \n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import Range1d\n",
    "\n",
    "from scipy import io\n",
    "import numpy as np\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from sklearn.metrics import euclidean_distances\n",
    "\n",
    "#this allows us to view the tangent angle distance between postures which \n",
    "#helps to develop an intuition of which postures are close and which\n",
    "#are far apart. \n",
    "\n",
    "g = io.loadmat('/Users/cyrilrocke/Documents/c_elegans/data/postures')\n",
    "postures = g.get('postures')\n",
    "\n",
    "\n",
    "seed = np.random.RandomState(seed=3)\n",
    "\n",
    "similarities = euclidean_distances(postures.T)\n",
    "\n",
    "mds = manifold.MDS(n_components=2, max_iter=5000, eps=1e-9, random_state=seed,\n",
    "                   dissimilarity=\"precomputed\", n_jobs=1)\n",
    "                   \n",
    "pos = mds.fit(similarities).embedding_\n",
    "\n",
    "def mtext(p, x, y, textstr):\n",
    "    p.text(x, y, text=[textstr],\n",
    "         text_color='steelblue', text_align=\"center\", text_font_size=\"10pt\")\n",
    "\n",
    "\n",
    "output_file(\"color_scatter.html\", title=\"postures MDS\")\n",
    "TOOLS=\"resize,crosshair,pan,wheel_zoom,box_zoom,reset,tap,previewsave,box_select,poly_select,lasso_select\"\n",
    "\n",
    "# create a new plot with a range set with a tuple\n",
    "p = figure(plot_width=400, plot_height=400, x_range=(-8, 10),y_range=(-8,8),tools=TOOLS)\n",
    "\n",
    "\n",
    "p.scatter(pos[:,0],pos[:,1],radius=0.2,fill_color='#FFDAB9', fill_alpha=0.6)\n",
    "\n",
    "for i in range(90):\n",
    "    mtext(p, [pos[:,0][i]], [pos[:,1][i]-0.15], str(i))\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Here's a visualization of the distance between the postures using. The numbers are consistent with the numbers\n",
    "####given to the posture templates above:\n",
    "<img src=\"http://localhost:8888/files/Untitled%20Folder%201/bokeh_postures_mds.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it must be noted that on average the variance explained by the best posture matches was quite good as shown by the graphs below. Each graph represents the postural variance explained(R2) during a 15 minute video. In red we have the average value for R2 and at the top of the graph you have an explanation of how often R2 is above the red line(i.e. the average value):\n",
    "\n",
    "<img src=\"http://localhost:8888/files/Untitled%20Folder%201/Untitled%20Folder/explained_variance_visualized.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####But, R2 and the tangent angle distance actually compute very different things and as the of R2 vs tangent angle distance shows below...the relationship isn't linear. In fact their outliers are different:\n",
    "<img src=\"http://localhost:8888/files/Untitled%20Folder%201/Untitled%20Folder/variance_explained_vs_errors.png\">\n",
    "\n",
    "-R2 outliers tend to be straight whereas tangent angle distance outliers tend to be curved. In fact, I think that using the R2 gain in choosing the number of templates isn't sound in this respect. I would stick with looking at the decline in the average tangent angle distance error. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's coming up next week:\n",
    "    1. Can we use a non-uniform time warping method to compress sequences in the manner {2,3,3,3,4,5,90}={2,3,4,5,90} without significant loss of information. And, does this require the assumption that C Elegans has discrete behavioral states?\n",
    "    2. Given the same environmental stimulus do a large number of worms of the same subspecies must have a common set of trigrams? Thanks to data that Andre Brown just recently sent over I will be able to answer this question. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
